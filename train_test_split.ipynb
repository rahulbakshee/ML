{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How train test split affects the accuracy \n",
    "Note: I do not own this code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description: using iris dataset we are trying to classify the three labels of iris flower. We will see how train/test size matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " importing train_test_split for splitting of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iter 1\n",
    "train size 50%\n",
    "accuracy 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.50, random_state = 123, stratify = y)\n",
    "\n",
    "print(\"all\", np.bincount(y)/float(len(y))*100)\n",
    "print(\"train\", np.bincount(train_y)/float(len(y))*100)\n",
    "print(\"test\", np.bincount(test_y)/float(len(y))*100)\n",
    "\n",
    "classifier.fit(train_X, train_y)\n",
    "pred_y = classifier.predict(test_X)\n",
    "\n",
    "print(\"accuracy \", np.sum(pred_y == test_y)/float(len(test_y))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iter 2\n",
    "train size 55%\n",
    "accuracy 95.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.55, random_state = 123, stratify = y)\n",
    "\n",
    "print(\"all\", np.bincount(y)/float(len(y))*100)\n",
    "print(\"train\", np.bincount(train_y)/float(len(y))*100)\n",
    "print(\"test\", np.bincount(test_y)/float(len(y))*100)\n",
    "\n",
    "classifier.fit(train_X, train_y)\n",
    "pred_y = classifier.predict(test_X)\n",
    "\n",
    "print(\"accuracy \", np.sum(pred_y == test_y)/float(len(test_y))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iter 3\n",
    "train size 45% accuracy 96.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.45, random_state = 123, stratify = y)\n",
    "\n",
    "print(\"all\", np.bincount(y)/float(len(y))*100)\n",
    "print(\"train\", np.bincount(train_y)/float(len(y))*100)\n",
    "print(\"test\", np.bincount(test_y)/float(len(y))*100)\n",
    "\n",
    "classifier.fit(train_X, train_y)\n",
    "pred_y = classifier.predict(test_X)\n",
    "\n",
    "print(\"accuracy \", np.sum(pred_y == test_y)/float(len(test_y))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that with varying train_test_split size we get varying accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# looping over train split size to get best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = np.linspace(.2, .8, 30)\n",
    "\n",
    "ac1 = 0\n",
    "ac = 0\n",
    "k = 0\n",
    "for i in ts:\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = i, random_state = 123, stratify = y)\n",
    "    classifier.fit(train_X, train_y)\n",
    "    pred_y = classifier.predict(test_X)\n",
    "\n",
    "    #print(\"accuracy \", np.sum(pred_y == test_y)/float(len(test_y))*100)\n",
    "    \n",
    "    ac1 = (np.sum(pred_y == test_y)/float(len(test_y))*100)\n",
    "    if ac1>ac:\n",
    "        ac = ac1\n",
    "        k = i\n",
    "print(\"max accuracy and train split size \", (ac, k))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
